{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move necessary helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_utilities import update_utilities_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist in destination folder, it is now removed\n",
      "File copied, now the file is available to import from the destinated path\n",
      "File already exist in destination folder, it is now removed\n",
      "File copied, now the file is available to import from the destinated path\n",
      "File already exist in destination folder, it is now removed\n",
      "File copied, now the file is available to import from the destinated path\n",
      "File already exist in destination folder, it is now removed\n",
      "File copied, now the file is available to import from the destinated path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "update_utilities_class(file_name=\"Transformer.py\",current_path=os.getcwd()).run()\n",
    "update_utilities_class(file_name=\"custom_text_dataset.py\",current_path=os.getcwd()).run()\n",
    "update_utilities_class(file_name=\"loss_functions.py\",current_path=os.getcwd()).run()\n",
    "update_utilities_class(file_name=\"train_test_loop.py\",current_path=os.getcwd()).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_functions import HelperFunctionsClass\n",
    "h = HelperFunctionsClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = h.convert_str_file_to_int_array(file_path=\"training_data/train_tokens.txt\",convert_to_torch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = h.convert_str_file_to_int_array(file_path=\"training_data/val_tokens.txt\",convert_to_torch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5101623, 561744)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_text_dataset import slideTokenizedTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512\n",
    "train_dataset = slideTokenizedTextDataset(full_txt=train_data, block_size=block_size)\n",
    "val_dataset = slideTokenizedTextDataset(full_txt=val_data, block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5101111, 561232)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_num_samples = 800000\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset,replacement=False,num_samples=train_num_samples)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_samples = 200000\n",
    "val_sampler = torch.utils.data.RandomSampler(val_dataset,replacement=False,num_samples=val_num_samples)\n",
    "val_loader = DataLoader(val_dataset,sampler=val_sampler,batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 3125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 2003 # 2000 vocab size + 3 special tokens\n",
    "transformer = Transformer.TransformerClass(vocab_size=2003,emb_dim=512,num_heads=8,n_layer=8,block_size=512, ff_multiplier=4,\n",
    "                                           dropout_rate_attention=0.1, dropout_rate_ff=0.2, dropout_rate_pos_enc=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Parameters 27.26 million\n"
     ]
    }
   ],
   "source": [
    "num_para = sum(p.numel() for p in transformer.parameters()) / 1e6\n",
    "print(f\"Total number of Parameters {round(num_para,2)} million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load(r\"baseline_vocb2000_experiments\\test_3.09 stats\\test weights\\test_best.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training stage 1\n",
    "**Rapid training with relatively higher lr, more validation check point, relatively lower number of validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_loop import train_test_loop_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.AdamW(params=transformer.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite=True\n",
    "num_epochs=1\n",
    "print_every = 855*2\n",
    "\n",
    "train_loop = train_test_loop_class(model=transformer,train_loader=train_loader,val_loader=val_loader,test_loader=None,\n",
    "                                   epochs=num_epochs, print_every_n_batch=print_every,device=device,\n",
    "                                   model_name=\"test_morelayer\",optimizer = optimizer, calculate_accuracy=False,\n",
    "                                   overwrite_message=overwrite,problem_type=\"Multiclass Classification\",\n",
    "                                   update_loss_fn=False, print_result=True, print_full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.overwrite_message = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10937, 1812)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_num_samples = 700000\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset,replacement=False,num_samples=train_num_samples)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler,drop_last=True)\n",
    "val_num_samples = 116000\n",
    "val_sampler = torch.utils.data.RandomSampler(val_dataset,replacement=False,num_samples=val_num_samples)\n",
    "val_loader = DataLoader(val_dataset,sampler=val_sampler,batch_size=batch_size,drop_last=True)\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.train_loader = train_loader\n",
    "train_loop.val_loader = val_loader\n",
    "train_loop.print_progress = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16abdfe8f6db4ae9b7b99031c27147af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10937 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1000 / 10937 || Average per-Batch Training Loss: 3.9907 || Average per-Batch Validation Loss: 3.9026\n",
      "Batch: 2000 / 10937 || Average per-Batch Training Loss: 3.9360 || Average per-Batch Validation Loss: 3.8435\n",
      "Batch: 3000 / 10937 || Average per-Batch Training Loss: 3.8818 || Average per-Batch Validation Loss: 3.7849\n",
      "Batch: 4000 / 10937 || Average per-Batch Training Loss: 3.8277 || Average per-Batch Validation Loss: 3.7312\n",
      "Batch: 5000 / 10937 || Average per-Batch Training Loss: 3.7759 || Average per-Batch Validation Loss: 3.6801\n",
      "Batch: 6000 / 10937 || Average per-Batch Training Loss: 3.7260 || Average per-Batch Validation Loss: 3.6347\n",
      "Batch: 7000 / 10937 || Average per-Batch Training Loss: 3.6819 || Average per-Batch Validation Loss: 3.5933\n",
      "Batch: 8000 / 10937 || Average per-Batch Training Loss: 3.6401 || Average per-Batch Validation Loss: 3.5548\n",
      "Batch: 9000 / 10937 || Average per-Batch Training Loss: 3.6003 || Average per-Batch Validation Loss: 3.5222\n",
      "Batch: 10000 / 10937 || Average per-Batch Training Loss: 3.5657 || Average per-Batch Validation Loss: 3.4918\n",
      "Batch: 10937 / 10937 || Average per-Batch Training Loss: 3.5339 || Average per-Batch Validation Loss: 3.4658\n",
      "\n",
      " All Done\n",
      "\n",
      "Overall training took 1.81 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Stage 2\n",
    "**slow fine-tuning with relatively lower lr, less validation check point, relatively higher number of validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "optimizer = torch.optim.AdamW(params=transformer.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite=True\n",
    "num_epochs=1\n",
    "print_every = 1250\n",
    "\n",
    "train_loop = train_test_loop_class(model=transformer,train_loader=train_loader,val_loader=val_loader,test_loader=None,\n",
    "                                   epochs=num_epochs, print_every_n_batch=print_every,device=device,\n",
    "                                   model_name=\"baseline_vocab2000\",optimizer = optimizer, calculate_accuracy=False,\n",
    "                                   overwrite_message=overwrite,problem_type=\"Multiclass Classification\",\n",
    "                                   update_loss_fn=False, print_result=True, print_full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e028804c6b9413bbf5e1e7c0446c62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1250 / 12500 || Average per-Batch Training Loss: 2.6905 || Average per-Batch Validation Loss: 3.0726\n",
      "Batch: 2500 / 12500 || Average per-Batch Training Loss: 2.6707 || Average per-Batch Validation Loss: 3.0727\n",
      "Batch: 3750 / 12500 || Average per-Batch Training Loss: 2.6572 || Average per-Batch Validation Loss: 3.0725\n",
      "Batch: 5000 / 12500 || Average per-Batch Training Loss: 2.6441 || Average per-Batch Validation Loss: 3.0733\n",
      "Batch: 6250 / 12500 || Average per-Batch Training Loss: 2.6330 || Average per-Batch Validation Loss: 3.0777\n",
      "Batch: 7500 / 12500 || Average per-Batch Training Loss: 2.6202 || Average per-Batch Validation Loss: 3.0791\n",
      "Batch: 8750 / 12500 || Average per-Batch Training Loss: 2.6109 || Average per-Batch Validation Loss: 3.0791\n",
      "Batch: 10000 / 12500 || Average per-Batch Training Loss: 2.5992 || Average per-Batch Validation Loss: 3.0818\n",
      "Batch: 11250 / 12500 || Average per-Batch Training Loss: 2.5898 || Average per-Batch Validation Loss: 3.0845\n",
      "Batch: 12500 / 12500 || Average per-Batch Training Loss: 2.5786 || Average per-Batch Validation Loss: 3.0872\n",
      "\n",
      " All Done\n",
      "\n",
      "Overall training took 2.34 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop.overwrite_message = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c0eade85b846e28f5694dc5aba6146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1250 / 12500 || Average per-Batch Training Loss: 2.5695 || Average per-Batch Validation Loss: 3.0878\n",
      "Batch: 2500 / 12500 || Average per-Batch Training Loss: 2.5584 || Average per-Batch Validation Loss: 3.0924\n",
      "Batch: 3750 / 12500 || Average per-Batch Training Loss: 2.5479 || Average per-Batch Validation Loss: 3.0942\n",
      "Batch: 5000 / 12500 || Average per-Batch Training Loss: 2.5387 || Average per-Batch Validation Loss: 3.0965\n",
      "Batch: 6250 / 12500 || Average per-Batch Training Loss: 2.5298 || Average per-Batch Validation Loss: 3.0997\n",
      "Batch: 7500 / 12500 || Average per-Batch Training Loss: 2.5203 || Average per-Batch Validation Loss: 3.1044\n",
      "Batch: 8750 / 12500 || Average per-Batch Training Loss: 2.5111 || Average per-Batch Validation Loss: 3.1059\n",
      "Batch: 10000 / 12500 || Average per-Batch Training Loss: 2.5021 || Average per-Batch Validation Loss: 3.1082\n",
      "Batch: 11250 / 12500 || Average per-Batch Training Loss: 2.4919 || Average per-Batch Validation Loss: 3.1106\n",
      "Batch: 12500 / 12500 || Average per-Batch Training Loss: 2.4849 || Average per-Batch Validation Loss: 3.1147\n",
      "\n",
      " All Done\n",
      "\n",
      "Overall training took 2.36 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop.model = transformer.to(device)\n",
    "train_loop.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "class generator:\n",
    "    def __init__(self, model, encoder, decoder, model_name):\n",
    "        self.model = model.cpu()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.model_name = model_name\n",
    "        self.folder_name = \"generated_text\"\n",
    "    \n",
    "    def _open_file(self):\n",
    "        if not os.path.exists(self.folder_name):\n",
    "            os.makedirs(self.folder_name)\n",
    "        self.f = open(os.path.join(self.folder_name,self.model_name)+\".txt\",\"a\")\n",
    "\n",
    "    \n",
    "    def generate_without_prompt(self, user_input, generation_length=300, block_size=512,default_start_token=True,pad_with=32):\n",
    "        self._open_file()\n",
    "        output_list = [user_input]\n",
    "        if default_start_token: user_input = '<|startofchapter|>' + user_input\n",
    "        # tokenize user input\n",
    "        input_tokens = torch.tensor(self.encoder(user_input),dtype=torch.long)\n",
    "        # pad tokens\n",
    "        if len(input_tokens) < block_size:\n",
    "            tokens = torch.full(size=(1,block_size),fill_value=pad_with,dtype=torch.long)\n",
    "            tokens[0,-len(input_tokens):] = input_tokens\n",
    "        else:\n",
    "            tokens = input_tokens[-block_size:].unsqueeze(0)\n",
    "        \n",
    "        m = f\"User input: {user_input}\\nGenerating----------------------------------------------------\\n\"\n",
    "        print(m)\n",
    "        self.f.write(\"\\n\\n\"+m+\"\\n\")\n",
    "\n",
    "        print_status = False\n",
    "        print_idx_start = 0\n",
    "        for i in range(generation_length):\n",
    "            if i % 30 == 1:\n",
    "                print_status = True\n",
    "            if (\".\" in output_list[-1] or \",\" in output_list[-1]) and print_status==True:\n",
    "                output_sequence = \"\".join(output_list[print_idx_start:])\n",
    "                print_idx_start = len(output_list)\n",
    "                print_status=False\n",
    "                print(output_sequence)\n",
    "                self.f.write(output_sequence+\"\\n\")\n",
    "            tokens_truncate = tokens[0,-block_size:]\n",
    "            logit = self.model(tokens_truncate)\n",
    "            logit = logit[0,-1,:]\n",
    "            prob = torch.nn.functional.softmax(logit,dim=0)\n",
    "            new_token = torch.multinomial(input=prob,num_samples=1)\n",
    "            tokens = torch.cat((tokens,new_token.unsqueeze(0)),dim=1)\n",
    "            output_list.append(self.decoder([new_token.item()]))\n",
    "        m = f\"\\nEnd of generation------------------------------------------------------------------\\n\"\n",
    "        print(m)\n",
    "        self.f.write(m+\"\\n\\n\")\n",
    "        self.f.close()\n",
    "        return output_list\n",
    "            \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from regex_bpe_tokenizer import ApplyTokenizer\n",
    "tokenizer = ApplyTokenizer(title=\"FantasyGPTv1\",vocab_size=2000,tokenizer_folder_path=os.getcwd())\n",
    "len(tokenizer.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(transformer,tokenizer.encode,tokenizer.decode,\"baseline_vocab2000_run2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: <|startofchapter|>Parmida wants to be a shadowhunter, and she \n",
      "Generating----------------------------------------------------\n",
      "\n",
      "Parmida wants to be a shadowhunter, and she ought to be angry.\n",
      " \"And if I look so a little closely eat?\" Emma said. Livvy smiled wryly. Then she appeared with a precise entaling coffee.\n",
      " She threw Cortana. \"I'm thirteen,\"\n",
      " Emma said. \"Just tell me I'll tell you everything.\" \"Brought iron and the others are packed,\" said Livvy. \"Please don't keep them in.\"\n",
      " \"We enjoy the gates. David they forget.\" \"Tiua says she remembered to whom--\" Livvy worried.\n",
      " Cameron pointed at the entrance to the entryway entrance.\n",
      " \"Run, Livvy in the car. She rarely told anyone this was ten seconds. She wanted to go through the gardens.\"\n",
      " Cameron made a horse pause. \"She told me things about her training. She left you so they'd never find out who takes you with the previous night.\"\n",
      " \"They called us,\" Livvy said. \"I didn't haven't seen you leave so much from anyone ever happy.\n",
      " It was the only thing you're protecting them.\" \"She always said that Sebastian was able to get out?\" Jace asked.\n",
      "\n",
      "End of generation------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input=\"Parmida wants to be a shadowhunter, and she \"\n",
    "output = gen.generate_without_prompt(user_input=user_input,generation_length=300,default_start_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
